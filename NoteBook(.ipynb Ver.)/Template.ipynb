{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e08495",
   "metadata": {},
   "source": [
    "# Pytorch Template\n",
    "+ made by JSY\n",
    "+ https://github.com/HideOnHouse/TorchBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc0930",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_tags\n",
    "label_tags = ['T-Shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
    "\n",
    "train_path = \"\"\n",
    "test_path = \"\"\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your Data Pre-Processing\n",
    "train_x, train_y = train_data.iloc[:, 1:], train_data.iloc[:, :1]\n",
    "test_x, test_y = test_data.iloc[:, 1:], test_data.iloc[:, :1]\n",
    "\n",
    "# data split\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, stratify=train_y, random_state=17, test_size=0.1)\n",
    "\n",
    "# Check Train, Valid, Test Image's Shape\n",
    "print(\"The Shape of Train Images: \", train_x.shape)\n",
    "print(\"The Shape of Valid Images: \", valid_x.shape)\n",
    "print(\"The Shape of Test Images: \", test_x.shape)\n",
    "\n",
    "# Check Train, Valid Label's Shape\n",
    "print(\"The Shape of Train Labels: \", train_y.shape)\n",
    "print(\"The Shape of Valid Labels: \", valid_y.shape)\n",
    "print(\"The Shape of Valid Labels: \", test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f1569",
   "metadata": {},
   "source": [
    "## Define Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78edb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(MyDataset, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pass\n",
    "\n",
    "    def show_item(self, idx=0):\n",
    "        feature, label = self.__getitem__(idx)\n",
    "\n",
    "        print(\"Feature's Shape : {}\".format(feature.shape))\n",
    "        print(\"Label's Shape : {}\".format(label.shape))\n",
    "\n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "train_dataset = MyDataset(train_x, train_y)\n",
    "valid_dataset = MyDataset(valid_x, valid_y)\n",
    "test_dataset = MyDataset(test_x, test_y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb0781",
   "metadata": {},
   "source": [
    "## Define Learning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fcafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(output, label):\n",
    "    o_val, o_idx = torch.max(output, dim=-1)\n",
    "    l_val, l_idx = torch.max(label, dim=-1)\n",
    "    return (o_idx == l_idx).sum().item()\n",
    "\n",
    "\n",
    "def train(model, device, optimizer, criterion, epochs, train_loader, valid_loader=None) -> dict:\n",
    "    \"\"\"\n",
    "    :param model: your model\n",
    "    :param device: your device(cuda or cpu)\n",
    "    :param optimizer: your optimizer\n",
    "    :param criterion: loss function\n",
    "    :param epoch: train epochs\n",
    "    :param train_loader: train dataset\n",
    "    :param valid_loader: valid dataset\n",
    "    :return: history dictionary that contains train_loss, train_acc, valid_loss, valid_acc as list\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'valid_loss': [],\n",
    "        'valid_acc': []\n",
    "    }\n",
    "    model.to(device)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = train_acc = 0\n",
    "\n",
    "        # in notebook\n",
    "        # pabr = notebook.tqdm(enumerate(train_loader), file=sys.stdout)\n",
    "\n",
    "        # in interpreter\n",
    "        pbar = tqdm(enumerate(train_loader), file=sys.stdout)\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            acc = calc_acc(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_acc += acc\n",
    "\n",
    "            acc = train_acc / (batch_idx * train_loader.batch_size + len(data))\n",
    "            pbar.set_postfix(epoch=f'{epoch}/{epochs}', loss='{:.6f}, acc={:.3f}'.format(loss, acc))\n",
    "        pbar.close()\n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc / len(train_loader.dataset)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "\n",
    "        if valid_loader is not None:\n",
    "            valid_loss, valid_acc = evaluate(model, device, criterion, valid_loader)\n",
    "\n",
    "            history['valid_loss'].append(valid_loss)\n",
    "            history['valid_acc'].append(valid_acc)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def evaluate(model, device, criterion, data_loader):\n",
    "    \"\"\"\n",
    "    :param model: your model\n",
    "    :param device: your device(cuda or cpu)\n",
    "    :param criterion: loss function\n",
    "    :param data_loader: valid or test Datasets\n",
    "    :return: (valid or test) loss and acc\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = total_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # in notebook\n",
    "        # pabr = notebook.tqdm(enumerate(valid_loader), file=sys.stdout)\n",
    "\n",
    "        # in interpreter\n",
    "        pbar = tqdm(enumerate(data_loader), file=sys.stdout)\n",
    "\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            data, target = data.to(device), target.to(device),\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            acc = calc_acc(output, target)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "\n",
    "            acc = total_acc / (batch_idx * data_loader.batch_size + len(data))\n",
    "            pbar.set_postfix(loss='{:.6f}, acc={:.3f}'.format(loss, acc))\n",
    "        pbar.close()\n",
    "\n",
    "    total_loss = total_loss / len(data_loader)\n",
    "    total_acc = total_acc / len(data_loader.dataset)\n",
    "\n",
    "    return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23694148",
   "metadata": {},
   "source": [
    "## Define Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe3f88d",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d181b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc7916",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "print(\"============================= Train =============================\")\n",
    "history = train(model, device, optimizer, criterion, 16, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35341e42",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "print(\"============================= Test =============================\")\n",
    "test_loss, test_acc = evaluate(model, device, test_loader, criterion)\n",
    "print(\"test loss : {:.6f}\".format(test_loss))\n",
    "print(\"test acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa2c00",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d4db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "# print(\"=========================== Inference ===========================\")\n",
    "# inference(model, device, infer_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806fa154",
   "metadata": {},
   "source": [
    "## Model Save & display history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_history(history):\n",
    "    train_loss = history[\"train_loss\"]\n",
    "    train_acc = history[\"train_acc\"]\n",
    "    valid_loss = history[\"valid_loss\"]\n",
    "    valid_acc = history[\"valid_acc\"]\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(train_loss, label=\"train\")\n",
    "    plt.plot(valid_loss, label=\"valid\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(train_acc, label=\"train\")\n",
    "    plt.plot(valid_acc, label=\"valid\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"model1\"\n",
    "torch.save(model, f\"models/{file_name}.pt\")\n",
    "with open(f\"models/{file_name}_history.pickle\", 'wb') as f:\n",
    "    pickle.dump(history, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# print(history)\n",
    "draw_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JSY_GPU",
   "language": "python",
   "name": "jsy_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
